{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7d9baf-a5f6-4aee-a150-734bcaf415e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "275c57c4-f47c-4d05-8899-756971622bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = \"multi_resample_config_v1.json\"\n",
    "\n",
    "config = dict()\n",
    "\n",
    "model_config = dict()\n",
    "model_config[\"name\"] = \"DynUNet\"  # network model name from MONAI\n",
    "# set the network hyper-parameters\n",
    "model_config[\"in_channels\"] = 4  # 4 input images for the BraTS challenge\n",
    "model_config[\"out_channels\"] = 1   # whole tumor, tumor core, enhancing tumor\n",
    "model_config[\"spatial_dims\"] = 3   # 3D input images\n",
    "model_config[\"deep_supervision\"] = False  # do not check outputs of lower layers\n",
    "model_config[\"strides\"] = [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]][:-1]  # number of downsampling convolutions\n",
    "model_config[\"filters\"] = [64, 96, 128, 192, 256, 384, 512, 768, 1024][:len(model_config[\"strides\"])]  # number of filters per layer\n",
    "model_config[\"kernel_size\"] = [[3, 3, 3]] * len(model_config[\"strides\"])  # size of the convolution kernels per layer\n",
    "model_config[\"upsample_kernel_size\"] = model_config[\"strides\"][1:]  # should be the same as the strides\n",
    "\n",
    "# put the model config in the main config\n",
    "config[\"model\"] = model_config\n",
    "\n",
    "config[\"optimizer\"] = {'name': 'Adam', \n",
    "                       'lr': 0.001}  # initial learning rate\n",
    "\n",
    "# define the loss\n",
    "config[\"loss\"] = {'name': 'DiceLoss', # from Monai\n",
    "                  'include_background': True,  # we do not have a label for the background, so this should be true (by \"include background\" monai means include channel 0)\n",
    "                  'sigmoid': True,  # transform the model logits to activations\n",
    "                  'batch': False}  \n",
    "\n",
    "# set the cross validation parameters\n",
    "config[\"cross_validation\"] = {'folds': 5,  # number of cross validation folds\n",
    "                              'seed': 25},  # seed to make the generation of cross validation folds consistent across different trials\n",
    "# set the scheduler parameters\n",
    "config[\"scheduler\"] = {'name': 'ReduceLROnPlateau', \n",
    "                       'patience': 20,  # wait 10 epochs with no improvement before reducing the learning rate\n",
    "                       'factor': 0.5,   # multiply the learning rate by 0.5\n",
    "                       'min_lr': 1e-08}  # stop reducing the learning rate once it gets to 1e-8\n",
    "\n",
    "# set the dataset parameters\n",
    "config[\"dataset\"] = {'name': 'SegmentationDatasetPersistent',  # 'Persistent' means that it will save the preprocessed outputs generated during the first epoch\n",
    "# However, using 'Persistent', does also increase the time of the first epoch compared to the other epochs, which should run faster\n",
    "  'desired_shape': [192, 192, 192],  # resize the images to this shape, increase this to get higher resolution images (increases computation time and memory usage)\n",
    "  'labels': [1],  # 1: tumor\n",
    "  'orientation': 'RAS',  # Force all the images to be the same orientation (Right-Anterior-Suppine)\n",
    "  'normalization': 'NormalizeIntensityD',  # z score normalize the input images to zero mean unit standard deviation\n",
    "  'normalization_kwargs': {'channel_wise': True, \"nonzero\": False},  # perform the normalization channel wise and include the background\n",
    "  'resample': True,  # resample the images when resizing them, otherwise the resize could crop out regions of interest\n",
    "  'crop_foreground': True,  # crop the foreground of the images\n",
    "  'foreground_percentile': 0.9,  # aggressive foreground cropping to make sure the empty space is taken out of the images\n",
    "  'training':  # the following arguments will only be applied to the training data.\n",
    "    {\n",
    "    'spatial_augmentations': [{'name': 'RandFlipD', 'spatial_axis': 0, 'prob': 0.5},\n",
    "                              {'name': 'RandFlipD', 'spatial_axis': 1, 'prob': 0.5},\n",
    "                              {'name': 'RandRotateD', 'prob': 0.5, 'range_x': 0.2, 'range_y': 0.2, 'range_z': 0.2}],\n",
    "    'intensity_augmentations': [{'name': 'RandScaleIntensityD', 'factors': 0.1, 'prob': 1.0},\n",
    "                                {'name': 'RandShiftIntensityD', 'offsets': 0.1, 'prob': 1.0}],\n",
    "    }\n",
    "                    }\n",
    "config[\"training\"] = {'batch_size': 2,  # number of image/label pairs to read at a time during training\n",
    "  'validation_batch_size': 2,  # number of image/label pairs to read at atime during validation\n",
    "  'amp': False,  # don't set this to true unless the model you are using is setup to use automatic mixed precision (AMP)\n",
    "  'early_stopping_patience': None,  # stop the model early if the validaiton loss stops improving\n",
    "  'n_epochs': 1000,  # number of training epochs, reduce this if you don't want training to run as long\n",
    "  'save_every_n_epochs': None,  # save the model every n epochs (otherwise only the latest model will be saved)\n",
    "  'save_last_n_models': None,  # save the last n models \n",
    "  'save_best': True}  # save the model that has the best validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "652520c3-0cb7-42a6-9392-98f2776850cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dwi_b0', 'dwi_b100', 'nb', 't1_gd', '']\n"
     ]
    }
   ],
   "source": [
    "# get the training filenames\n",
    "config[\"training_filenames\"] = list()\n",
    "ground_truth_filenames = sorted(glob.glob(\"./aligned/*/*/*NB*.nii*\"))\n",
    "for label_filename in ground_truth_filenames:\n",
    "    subject, visit = label_filename.split(\"/\")[-3:-1]\n",
    "    filenames = [os.path.abspath(fn) for fn in sorted(glob.glob(os.path.join(os.path.dirname(label_filename), \"*\")))]\n",
    "    n_features = len(filenames) \n",
    "    feature_modalities = [\"_\".join(fn.split(\"_\")[3:-1]).strip(\"8 \").lower() for fn in filenames]\n",
    "    t1_filename = filenames[feature_modalities.index(\"T1_gd\".lower())]\n",
    "    assert os.path.exists(t1_filename)\n",
    "    \n",
    "    if len(feature_modalities) < 5:\n",
    "        continue\n",
    "    \n",
    "    if \"T2\".lower() not in feature_modalities:\n",
    "        for filename in filenames:\n",
    "            if \"T2\" in filename:\n",
    "                t2_fn = filename\n",
    "        # print(t2_fn)\n",
    "        print(feature_modalities)\n",
    "    else:\n",
    "        t2_fn = filenames[feature_modalities.index(\"T2\".lower())]\n",
    "    assert os.path.exists(t2_fn)\n",
    "    \n",
    "    if \"DWI_b0\".lower() not in feature_modalities:\n",
    "        for filename in filenames:\n",
    "            if \"DWI\" in filename and \"b0\" in filename:\n",
    "                dwi_b0 = filename\n",
    "        # print(dwi_b0)\n",
    "    else:\n",
    "        dwi_b0 = filenames[feature_modalities.index(\"DWI_b0\".lower())]\n",
    "    assert os.path.exists(dwi_b0)\n",
    "\n",
    "    if \"DWI_b100\".lower() not in feature_modalities:\n",
    "        for filename in filenames:\n",
    "            if \"DWI\" in filename and \"b100\" in filename:\n",
    "                dwi_b100 = filename\n",
    "        # print(dwi_b100)\n",
    "    else:\n",
    "        dwi_b100 = filenames[feature_modalities.index(\"DWI_b100\".lower())]\n",
    "    assert os.path.exists(dwi_b100)\n",
    "\n",
    "    # print(t2_fn)\n",
    "    config[\"training_filenames\"].append({\"image\": [t1_filename, t2_fn, dwi_b0, dwi_b100], \"label\": label_filename})\n",
    "with open(config_filename, \"w\") as op:\n",
    "    json.dump(config, op, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7489857f-17d8-43ea-a9c6-95ab5900c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:08<00:33,  4.18s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "affine matrix of all images should be the same for channel-wise concatenation. Got [[-9.09744143e-01  4.17321585e-02  6.15315586e-02  1.63692520e+02]\n [-3.92322913e-02 -9.08636808e-01  9.93195400e-02  1.44127029e+02]\n [ 3.97835933e-02  5.82573116e-02  1.50500500e+00 -5.72437683e+02]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] and [[-9.11458313e-01 -4.17198098e-05  1.49980042e-04  1.73884186e+02]\n [ 4.22855992e-05 -9.11440492e-01  9.44507215e-03  1.53154114e+02]\n [ 9.02942920e-05  5.70288487e-03  1.50952148e+00 -4.98229950e+02]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m loader \u001b[38;5;241m=\u001b[39m LoadImage(image_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_filenames\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m62\u001b[39m:]):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/brats/lib/python3.11/site-packages/monai/transforms/io/array.py:290\u001b[0m, in \u001b[0;36mLoadImage.__call__\u001b[0;34m(self, filename, reader)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot find a suitable reader for file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Please install the reader libraries, see also the installation instructions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   The current registered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreaders\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    289\u001b[0m img_array: NdarrayOrTensor\n\u001b[0;32m--> 290\u001b[0m img_array, meta_data \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m img_array \u001b[38;5;241m=\u001b[39m convert_to_dst_type(img_array, dst\u001b[38;5;241m=\u001b[39mimg_array, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(meta_data, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/brats/lib/python3.11/site-packages/monai/data/image_reader.py:949\u001b[0m, in \u001b[0;36mNibabelReader.get_data\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         header[MetaKeys\u001b[38;5;241m.\u001b[39mORIGINAL_CHANNEL_DIM] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_dim\n\u001b[0;32m--> 949\u001b[0m     \u001b[43m_copy_compatible_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompatible_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _stack_images(img_array, compatible_meta), compatible_meta\n",
      "File \u001b[0;32m~/.conda/envs/brats/lib/python3.11/site-packages/monai/data/image_reader.py:128\u001b[0m, in \u001b[0;36m_copy_compatible_dict\u001b[0;34m(from_dict, to_dict)\u001b[0m\n\u001b[1;32m    126\u001b[0m affine_key, shape_key \u001b[38;5;241m=\u001b[39m MetaKeys\u001b[38;5;241m.\u001b[39mAFFINE, MetaKeys\u001b[38;5;241m.\u001b[39mSPATIAL_SHAPE\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m affine_key \u001b[38;5;129;01min\u001b[39;00m from_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(from_dict[affine_key], to_dict[affine_key]):\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maffine matrix of all images should be the same for channel-wise concatenation. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfrom_dict[affine_key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_dict[affine_key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape_key \u001b[38;5;129;01min\u001b[39;00m from_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(from_dict[shape_key], to_dict[shape_key]):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial_shape of all images should be the same for channel-wise concatenation. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfrom_dict[shape_key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_dict[shape_key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: affine matrix of all images should be the same for channel-wise concatenation. Got [[-9.09744143e-01  4.17321585e-02  6.15315586e-02  1.63692520e+02]\n [-3.92322913e-02 -9.08636808e-01  9.93195400e-02  1.44127029e+02]\n [ 3.97835933e-02  5.82573116e-02  1.50500500e+00 -5.72437683e+02]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]] and [[-9.11458313e-01 -4.17198098e-05  1.49980042e-04  1.73884186e+02]\n [ 4.22855992e-05 -9.11440492e-01  9.44507215e-03  1.53154114e+02]\n [ 9.02942920e-05  5.70288487e-03  1.50952148e+00 -4.98229950e+02]\n [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]."
     ]
    }
   ],
   "source": [
    "from monai.transforms import LoadImage\n",
    "import tqdm\n",
    "loader = LoadImage(image_only=True)\n",
    "for item in tqdm.tqdm(config[\"training_filenames\"][62:]):\n",
    "    loader(item[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2aec4cfe-2a54-44cd-9a9d-ffaa02a3d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.1146e-01, -4.1720e-05,  1.4998e-04,  1.7388e+02],\n",
      "        [ 4.2286e-05, -9.1144e-01,  9.4451e-03,  1.5315e+02],\n",
      "        [ 9.0294e-05,  5.7029e-03,  1.5095e+00, -4.9823e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-9.0974e-01,  4.1732e-02,  6.1532e-02,  1.6369e+02],\n",
      "        [-3.9232e-02, -9.0864e-01,  9.9320e-02,  1.4413e+02],\n",
      "        [ 3.9784e-02,  5.8257e-02,  1.5050e+00, -5.7244e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-9.1146e-01, -4.1720e-05,  1.4998e-04,  1.7388e+02],\n",
      "        [ 4.2286e-05, -9.1144e-01,  9.4451e-03,  1.5315e+02],\n",
      "        [ 9.0294e-05,  5.7029e-03,  1.5095e+00, -4.9823e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-9.1146e-01, -4.1720e-05,  1.4998e-04,  1.7388e+02],\n",
      "        [ 4.2286e-05, -9.1144e-01,  9.4451e-03,  1.5315e+02],\n",
      "        [ 9.0294e-05,  5.7029e-03,  1.5095e+00, -4.9823e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "loader = LoadImage(image_only=True)\n",
    "for fn in item['image']:\n",
    "    image = loader(fn)\n",
    "    print(image.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec5748cf-407c-40dd-a190-2f9858d9ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20190424/PT_81_DWI_b100_20190424.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20190424/PT_81_T2_20190424.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20190424/PT_81_DWI_b0_20190424.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20190424/PT_81_NB_20190424.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20190424/PT_81_T1_gd_20190424.nii',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_NB_20200129.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_DWI_b0_20200129.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_T1_gd_20200129.nii',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_DWI_b100_20200129.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_T2_20200129.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20191003/PT_81_T1_gd_20191003.nii',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20191003/PT_81_NB_20191003.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20191003/PT_81_DWI_b100_20191003.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20191003/PT_81_T2_20191003.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20191003/PT_81_DWI_b0_20191003.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_NB_20200515.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_DWI_b0_20200515.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_t2_20200515.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_DWI_b100_20200515.nii.gz',\n",
       " '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_T1_gd_20200515.nii']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2471dfc1-7554-4823-93be-f97687d6e062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': ['/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_T1_gd_20200129.nii',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_T2_20200129.nii.gz',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_DWI_b0_20200129.nii.gz',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_DWI_b100_20200129.nii.gz'],\n",
       "  'label': './aligned/PT_81/20200129/PT_81_NB_20200129.nii.gz'},\n",
       " {'image': ['/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_T1_gd_20200515.nii',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_T2_20200129.nii.gz',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_DWI_b0_20200515.nii.gz',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_DWI_b100_20200515.nii.gz'],\n",
       "  'label': './aligned/PT_81/20200515/PT_81_NB_20200515.nii.gz'},\n",
       " {'image': ['/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_83/20191129/PT_83_T1_gd_20191129.nii',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_83/20191129/PT_83_T2_20191129.nii.gz',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_83/20191129/PT_83_DWI_b0_20191129.nii.gz',\n",
       "   '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_83/20191129/PT_83_DWI_b100_20191129.nii.gz'],\n",
       "  'label': './aligned/PT_83/20191129/PT_83_NB_20191129.nii.gz'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['training_filenames'][63:66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a848727-fa64-4a31-9ef5-561df4dfca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1518ba0-fb9f-4503-bf71-6d49dfc3a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = ants.image_read('/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_t2_20200515.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5da1fbd9-42cb-44fd-8bc5-45eb60172038",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = ants.image_read(item['image'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "798542bb-719e-4545-9b43-ff6c42ef6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ants.registration(fixed=t1, moving=t2, type_of_transform='QuickRigid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc9abf9d-66c8-47ac-a321-04d8a0ab89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ants.image_write(result['warpedmovout'], \"test.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "305c4470-c8c9-4d45-8b40-fa5115c73124",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = loader(\"test.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c52cdde-4ffd-4351-8f60-e1c4e58163b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.1146e-01, -4.1720e-05,  1.4998e-04,  1.7388e+02],\n",
       "        [ 4.2286e-05, -9.1144e-01,  9.4451e-03,  1.5315e+02],\n",
       "        [ 9.0294e-05,  5.7029e-03,  1.5095e+00, -4.9823e+02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66feae1e-5200-4bed-893b-3c3fa20fac5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.1146e-01, -4.1720e-05,  1.4998e-04,  1.7388e+02],\n",
       "        [ 4.2286e-05, -9.1144e-01,  9.4451e-03,  1.5315e+02],\n",
       "        [ 9.0294e-05,  5.7029e-03,  1.5095e+00, -4.9823e+02],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader('/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_t2_20200515.nii.gz').affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b81e05f0-c110-4643-acee-20f698aae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "559e5899-8928-4e22-8445-7af6d96735af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200129/PT_81_T2_20200129.nii.gz'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move(\"test.nii.gz\", '/lustre/work/aizenberg/dgellis/MICCAI23/code/3DUnetCNN/examples/sppin/aligned/PT_81/20200515/PT_81_t2_20200515.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9934e7-ae59-4c18-9585-e06b94acf02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7265a7-fc4d-49ea-bcde-d29fc33d79bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c1508-17ed-462f-b6ae-b3155cceecbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20b8818-0a00-45dc-bde3-b12023badd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training filenames\n",
    "config[\"training_filenames\"] = list()\n",
    "ground_truth_filenames = sorted(glob.glob(\"./preprocessed/*/*/*.nii.gz\"))\n",
    "for label_filename in ground_truth_filenames:\n",
    "    subject, visit = label_filename.split(\"/\")[-3:-1]\n",
    "    filenames = sorted(glob.glob(os.path.join(\"train\", subject, visit, f\"*.nii*\")))\n",
    "    n_features = len(filenames) \n",
    "    feature_modalities = [\"_\".join(fn.split(\"_\")[3:-1]) for fn in filenames]\n",
    "    t1_filename = filenames[feature_modalities.index(\"T1_gd\")]\n",
    "    assert os.path.exists(t1_filename)\n",
    "    config[\"training_filenames\"].append({\"image\": t1_filename, \"label\": label_filename})\n",
    "\n",
    "with open(config_filename, \"w\") as op:\n",
    "    json.dump(config, op, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f01a52-8b65-4c97-bbd1-c4b29011eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4250fed5-5b82-49bf-8576-54da8cbb5af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "quantile() q must be in the range [0, 1] but got 1.1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: quantile() q must be in the range [0, 1] but got 1.1"
     ]
    }
   ],
   "source": [
    "torch.quantile(torch.rand(100), 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbab2ece-bb05-4ac3-be15-15ae9690c06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853981633974483"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae42b42-202b-453d-8aad-81f0a9c321c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cba1201-49d3-42bc-b474-e0bac4f2ece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "360/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a8741be-a583-4133-859d-c06d8b65e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.729577951308232"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1/torch.pi) * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06262e3-b35b-46bc-8228-c02d22a56040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (brats)",
   "language": "python",
   "name": "brats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
